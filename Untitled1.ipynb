{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import essential packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib\n",
    "import re\n",
    "import numpy\n",
    "import operator\n",
    "from scipy import stats as sta\n",
    "import seaborn as sns\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from scipy.interpolate import spline\n",
    "import operator\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De novo assembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## invoke supernova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invoke_supernova(supernovapath, inpath, outpath, prefix, maxreads, style):\n",
    "    os.system('cd '+outpath)\n",
    "    os.system(supernovapath+'/supernova run --id='+prefix+' --fastqs='+inpath+' --maxreads='+maxreads)\n",
    "    os.system(supernovapath+'/supernova mkoutput --asmdir='outpath+'/prefix'+'/outs/assembly --outprefix='+outpath+'/'+prefix+'+ --style='+style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## invoke abyss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invoke_abyss(clean_fastq_barcode,outpath,prefix,np,name,k,q,l,s,n,S,N,B,H,kc):\n",
    "    reform_fastq_barcode(clean_fastq_barcode,outpath+'/BC_new.fastq')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## invoke spades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invoke_spades(clean_fastq_barcode,outpath,prefix)\n",
    "    reform_fastq_barcode(clean_fastq_barcode,outpath+'/BC_new.fastq')\n",
    "    os.system('spades.py --12 '+outpath+'/BC_new.fastq'+' -o '+outpath+'/'+prefix)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facilitate programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reform barcode info in clean fastq for arcs format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reform_fastq_barcode(clean_file,reform_file):\n",
    "    old_fastq = open(clean_file,\"r\")\n",
    "    new_fastq = open(reform_file,\"w\")\n",
    "    line_index=0\n",
    "    for line in old_fastq:\n",
    "        if line_index%4==0:\n",
    "            A=line.split(' ')\n",
    "            barcode=A[1]\n",
    "            new_fastq.write(A[0]+'_'+barcode[5:21]+'\\n')\n",
    "            line_index+=1\n",
    "        else:\n",
    "            new_fastq.write(line)\n",
    "            line_index+=1\n",
    "    old_fastq.close()\n",
    "    new_fastq.close()\n",
    "    return 0\n",
    "#dir0=sys.argv[1]\n",
    "#X=reform_fastq_title(dir0+'/barcoded.fastq',dir0+'/new.fastq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate length of reference genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Cal_ref_len(in_file):\n",
    "    f_ref=open(in_file,'r')\n",
    "    index=0\n",
    "    length=0\n",
    "    for line in f_ref:\n",
    "        if index==0:\n",
    "            index+=1\n",
    "            continue\n",
    "        else:\n",
    "            A=line.strip('\\n')\n",
    "            length+=len(A)\n",
    "    f_ref.close()\n",
    "    return length    \n",
    "\n",
    "\n",
    "length=Cal_ref_len('/scratch/users/zhanglu2/myproject/simulation/WGS_sim/parameter_simulation/mask_human/Homo_sapiens.GRCh38.dna_rm.chromosome_noN.19.fa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate contig files for SuperNova and ARCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_config_from_fasta(megabubble_file,contig_file):\n",
    "    fw = open(contig_file,\"w\")\n",
    "    f =  open(megabubble_file,\"r\")\n",
    "    flag = 0\n",
    "    N100 = \"N\"*11 + \"+\"\n",
    "    step = 1\n",
    "    contig = \"\"\n",
    "    curr = 0\n",
    "    for line in f:\n",
    "        curr += 1\n",
    "        if line[0]== \">\":\n",
    "            flag = 1\n",
    "            # process the previous one\n",
    "            if contig != \"\":\n",
    "                all_contigs = re.split(N100,contig)\n",
    "                for one_contig in all_contigs:\n",
    "                    fw.writelines(\">\" + str(step)+ \"\\n\")\n",
    "                    step += 1\n",
    "                    fw.writelines(one_contig + \"\\n\")\n",
    "                contig = \"\"\n",
    "            continue\n",
    "        if flag == 1:\n",
    "            contig += line.strip(\"\\n\")\n",
    "    all_contigs = re.split(N100,contig)\n",
    "    for one_contig in all_contigs:\n",
    "        fw.writelines(\">\" + str(step) + \"\\n\")\n",
    "        fw.writelines(one_contig + \"\\n\")\n",
    "        step+=1\n",
    "    print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate order files for SuperNova and ARCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_config_info_fasta(megabubble_file,contig_file):\n",
    "    fw = open(contig_file,\"w\")\n",
    "    f = open(megabubble_file,\"r\")\n",
    "    flag = 0\n",
    "    N100 = \"N\"*11 + \"+\"\n",
    "    step = 1\n",
    "    scaffold_num = 1\n",
    "    contig = \"\"\n",
    "    curr = 0\n",
    "    for line in f:\n",
    "        print(curr)\n",
    "        curr += 1\n",
    "        if line[0]== \">\":\n",
    "            flag = 1\n",
    "            # process the previous one\n",
    "            if contig != \"\":\n",
    "                all_contigs = re.split(N100,contig)\n",
    "                order = 1\n",
    "                for one_contig in all_contigs:\n",
    "                    fw.writelines(str(scaffold_num) + \"\\t\" + str(step)+\"\\t\"+ str(order)+\"\\n\")\n",
    "                    order += 1\n",
    "                    step += 1\n",
    "                contig = \"\"\n",
    "                scaffold_num += 1\n",
    "            continue\n",
    "        if flag == 1:\n",
    "            contig += line.strip(\"\\n\")\n",
    "    all_contigs = re.split(N100,contig)\n",
    "    order = 1\n",
    "    for one_contig in all_contigs:\n",
    "        fw.writelines(str(scaffold_num) + \"\\t\" + str(step)+ \"\\t\" + str(order) + \"\\n\")\n",
    "        order += 1\n",
    "        step+=1\n",
    "    print(\"finished\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## abyss_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invoke_abyss_arcs(bwapath, samtoolspath, arcspath, maketsvpath, reform_fastq, scaffolds_fasta, outpath):\n",
    "    os.system('cd '+outpath)\n",
    "    os.system('cat 'scaffolds_fasta+' | perl -ne \\'chomp;if(/^\\>/){$ct++;print \">$ct\\n\";}else{print \"$_\\n\";}\\' > ./abyss-scaffolds-renamed.fa')\n",
    "    os.system(bwapath+'/bwa index abyss-scaffolds-renamed.fa')\n",
    "    os.system(bwapath+'/bwa mem -t 32 abyss-scaffolds-renamed.fa -p '+reform_fastq+' | '+samtoolspath+'/samtools view -Sb - | +'samtoolspath+'/samtools sort -n -o ./Sorted_abyss_scaffold.bam')\n",
    "    os.system('touch alignment_scaffold_abyss.fof')\n",
    "    os.system('cat Sorted_abyss_scaffold.bam>alignment_scaffold_abyss.fof')\n",
    "    os.system(arcspath+'/arcs -f abyss-scaffolds-renamed.fa -a alignment_scaffold_abyss.fof -b scaffold_abyss')\n",
    "    os.system('python '+maketsvpath+'/makeTSVfile.py scaffold_abyss_original.gv scaffold_abyss.tigpair_checkpoint.tsv abyss-scaffolds-renamed.fa')\n",
    "    os.system('touch empty.fof')\n",
    "    os.system('LINKS -f abyss-scaffolds-renamed.fa -s empty.fof -b scaffold_abyss')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPAdes_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invoke_spades_arcs(bwapath, samtoolspath, arcspath, maketsvpath, reform_fastq, scaffolds_fasta, outpath):\n",
    "    os.system('cd '+outpath)\n",
    "    os.system('cat '+scaffolds_fasta+' | perl -ne \\'chomp;if(/^\\>/){$ct++;print \">$ct\\n\";}else{print \"$_\\n\";}\\' > ./spades-scaffolds-renamed.fa')\n",
    "    os.system(bwapath+'/bwa index spades-scaffolds-renamed.fa')\n",
    "    os.system(bwapath+'/bwa mem -t 32 spades-scaffolds-renamed.fa -p '+reform_fastq+' | '+samtoolspath+'/samtools view -Sb - | +'samtoolspath+'/samtools sort -n -o ./Sorted_spades_scaffold.bam')\n",
    "    os.system('touch alignment_scaffold_spades.fof')\n",
    "    os.system('cat Sorted_spades_scaffold.bam>alignment_scaffold_spades.fof')\n",
    "    os.system(arcspath+'/arcs -f spades-scaffolds-renamed.fa -a alignment_scaffold_spades.fof -b scaffold_spades')\n",
    "    os.system('python '+maketsvpath+'/makeTSVfile.py scaffold_spades_original.gv scaffold_spades.tigpair_checkpoint.tsv spades-scaffolds-renamed.fa')\n",
    "    os.system('touch empty.fof')\n",
    "    os.system('LINKS -f abyss-scaffolds-renamed.fa -s empty.fof -b scaffold_spades')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluation of assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## invoke quast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invoke_quast(quastpath, thread, label_list, fasta_list, outpath, prefix):\n",
    "    os.system('cd '+outpath)\n",
    "    fastqstring=\"\"\n",
    "    for fasta in fasta_list:\n",
    "        fastqstring=fastqstring+' '+fasta\n",
    "    os.system(quastpath+'/quast.py --extensive-mis-size 100 --fast --no-snps --threads '+thread+' --labels '+label_list+' '+fastqstring+' -R '+reference+' -o '+prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate reference length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Cal_ref_len(in_file):\n",
    "    f_ref=open(in_file,'r')\n",
    "    namelist=[]\n",
    "    lenlist=[]\n",
    "    index=0\n",
    "    length=0\n",
    "    totallength=0\n",
    "    for line in f_ref:\n",
    "        if line[0]==\">\":\n",
    "            namelist.append(line[1:])\n",
    "            if index!=0:\n",
    "                lenlist.append(length)\n",
    "                length=0\n",
    "        else:\n",
    "            A=line.strip('\\n')\n",
    "            length+=len(A)\n",
    "            totallength=totallength+len(A)\n",
    "        index+=1\n",
    "        lenlist.append(length)\n",
    "    f_ref.close()\n",
    "    return namelist,lenlist,totallength     \n",
    "#length=Cal_ref_len('/scratch/users/zhanglu2/myproject/simulation/WGS_sim/parameter_simulation/mask_human/Homo_sapiens.GRCh38.dna_rm.chromosome_noN.19.fa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Contig N50 and NA50 from quast result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_quast_info(outpath,prefix):\n",
    "    in_file=outpath+'/'+prefix+'/report.txt'\n",
    "    f_report=open(in_file,'r')\n",
    "    ContigN50=[]\n",
    "    ContigNA50=[]\n",
    "    for line in f_report:\n",
    "        line1=line.strip('\\n')\n",
    "        line2=line1.split('\\t')\n",
    "        if line2[0]='N50':\n",
    "            index=0\n",
    "            for N50value in line2:\n",
    "                if index!=0:\n",
    "                    ContigN50.append(N50value)\n",
    "                index+=1\n",
    "        if line2[0]='NA50': \n",
    "            index=0\n",
    "            for NA50value in line2:\n",
    "                if index!=0:\n",
    "                    ContigNA50.append(NA50value)\n",
    "                index+=1\n",
    "    return CongitN50,ContigNA50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Scaffold statistics and contig NCX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Contig alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class aligncontig(object):#class 'aligncontig' to store alignment information for contigs,\n",
    "          def __init__(self):\n",
    "            self.start=0 # start of contig alignment ,\n",
    "            self.end=0   # end of contig alignment ,\n",
    "            #self.length=0 # total length including gap,\n",
    "            self.alignlength=0 #total length without misassemblies,\n",
    "            self.forward=1\n",
    "            self.misstart=[] #list for the starts of aligned contigs, which may include the breakpoints of misassemblies,\n",
    "            self.misend=[]   #list for the ends of aligned contigs, which may include the breakpoints of misassemblies,\n",
    "def alignment_contig_coordinate(tsv_file,chr_id,chr_len):\n",
    "        f_tsv = open(tsv_file,'r')\n",
    "        count = 0\n",
    "        contig_dict = defaultdict(aligncontig)\n",
    "        start_align=[]\n",
    "        end_align=[]\n",
    "        start_contig=[]\n",
    "        end_contig=[]\n",
    "        offset_array=[]\n",
    "        offset_array.append(0)\n",
    "        offset=0\n",
    "        for length_chr in chr_len:\n",
    "            offset=offset+length_chr\n",
    "            offset_array.append(offset)\n",
    "        alignlength=0\n",
    "        processid=0\n",
    "        for line in f_tsv:\n",
    "            data=line.rsplit()\n",
    "            if count==0:\n",
    "                count+=1\n",
    "                continue\n",
    "            elif count%2 == 1:\n",
    "                data=line.rsplit()\n",
    "                if len(data)==4:\n",
    "                    continue\n",
    "                index_offset=chr_id.index(data[4])\n",
    "                offset_add=offset_array[index_offset]\n",
    "                if processid==0:\n",
    "                    processid=int(data[5])\n",
    "                    start_align.append(int(data[0])+offset_add)\n",
    "                    end_align.append(int(data[1])+offset_add)\n",
    "                    alignlength=alignlength+int(data[1])-int(data[0])+1\n",
    "                    start_contig.append(int(data[2]))\n",
    "                    end_contig.append(int(data[3]))\n",
    "                elif processid==int(data[5]):\n",
    "                    if int(data[0])<=int(data[1]):\n",
    "                        start_align.append(int(data[0])+offset_add)\n",
    "                        end_align.append(int(data[1])+offset_add)\n",
    "                        alignlength=alignlength+int(data[1])-int(data[0])+1\n",
    "                    else:\n",
    "                        start_align.append(int(data[1])+offset_add)\n",
    "                        end_align.append(int(data[0])+offset_add)\n",
    "                        alignlength=alignlength+int(data[1])-int(data[0])+1\n",
    "                    start_contig.append(int(data[2]))\n",
    "                    end_contig.append(int(data[3]))\n",
    "                else:\n",
    "                    Contig=aligncontig()\n",
    "                    Contig.start=min(start_align)\n",
    "                    Contig.end=max(end_align)\n",
    "                    Contig.misstart=start_align\n",
    "                    Contig.misend=end_align\n",
    "                    Contig.alignlength=alignlength\n",
    "                    if start_contig[0]<end_contig[0]:\n",
    "                        Contig.forward=1\n",
    "                    else:\n",
    "                        Contig.forward=2\n",
    "                    contig_dict[processid]=Contig\n",
    "                    start_align=[]\n",
    "                    end_align=[]\n",
    "                    start_contig=[]\n",
    "                    end_contig=[]\n",
    "                    alignlength=0\n",
    "                    processid=int(data[5])\n",
    "                    if int(data[0])<=int(data[1]):\n",
    "                        start_align.append(int(data[0])+offset_add)\n",
    "                        end_align.append(int(data[1])+offset_add)\n",
    "                        alignlength=alignlength+int(data[1])-int(data[0])+1\n",
    "                    else:\n",
    "                        start_align.append(int(data[1])+offset_add)\n",
    "                        end_align.append(int(data[0])+offset_add)\n",
    "                        alignlength=alignlength+int(data[1])-int(data[0])+1\n",
    "                    start_contig.append(int(data[2]))\n",
    "                    end_contig.append(int(data[3])) \n",
    "            count=count+1\n",
    "        contig=aligncontig()\n",
    "        Contig.start=min(start_align)\n",
    "        Contig.end=max(end_align)\n",
    "        Contig.misstart=start_align\n",
    "        Contig.misend=end_align\n",
    "        if start_contig[0]<end_contig[0]:\n",
    "               Contig.forward=1\n",
    "        else:\n",
    "               Contig.forward=2\n",
    "        Contig.alignlength=alignlength\n",
    "        contig_dict[processid]=Contig\n",
    "        return contig_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Input contig alignment breaked by misassembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alignment_miss_contig(tsv_file,chr_id,chr_len):\n",
    "        f_tsv = open(tsv_file,'r')\n",
    "        count = 0\n",
    "        contig_dict = defaultdict(aligncontig)\n",
    "        start_align=[]\n",
    "        end_align=[]\n",
    "        start_contig=[]\n",
    "        end_contig=[]\n",
    "        alignlength=0\n",
    "        processid=0\n",
    "        contig_status=1\n",
    "        indexid=0\n",
    "        offset_array=[]\n",
    "        offset_array.append(0)\n",
    "        offset=0\n",
    "        for length_chr in chr_len:\n",
    "            offset=offset+length_chr\n",
    "            offset_array.append(offset)\n",
    "        for line in f_tsv:\n",
    "            if count==0:\n",
    "                count+=1\n",
    "                continue\n",
    "            elif count%2==0:\n",
    "                data=line.rsplit()\n",
    "                if data[0]=='relocation,':\n",
    "                    contig_status=0            \n",
    "            elif count%2 == 1:\n",
    "                data=line.rsplit()\n",
    "                if len(data)==4:\n",
    "                    continue\n",
    "                index_offset=chr_id.index(data[4])\n",
    "                offset_add=offset_array[index_offset]\n",
    "                if processid==0:\n",
    "                    processid=int(data[5])\n",
    "                    start_align.append(int(data[0])+offset_add)\n",
    "                    end_align.append(int(data[1])+offset_add)\n",
    "                    start_contig.append(int(data[2]))\n",
    "                    end_contig.append(int(data[3]))\n",
    "                    alignlength=alignlength+int(data[1])-int(data[0])+1\n",
    "                elif processid==int(data[5]) and contig_status==1:\n",
    "                    if int(data[0])<=int(data[1]):\n",
    "                        start_align.append(int(data[0])+offset_add)\n",
    "                        end_align.append(int(data[1])+offset_add)\n",
    "                        alignlength=alignlength+int(data[1])-int(data[0])+1\n",
    "                    else:\n",
    "                        start_align.append(int(data[1])+offset_add)\n",
    "                        end_align.append(int(data[0])+offset_add)\n",
    "                        alignlength=alignlength+int(data[1])-int(data[0])+1\n",
    "                    start_contig.append(int(data[2]))\n",
    "                    end_contig.append(int(data[3]))\n",
    "                else:\n",
    "                    contig_status=1\n",
    "                    Contig=aligncontig()\n",
    "                    Contig.start=min(start_align)\n",
    "                    Contig.end=max(end_align)\n",
    "                    Contig.alignlength=alignlength\n",
    "                    if start_contig[0]<end_contig[0]:\n",
    "                        Contig.forward=1\n",
    "                    else:\n",
    "                        Contig.forward=2\n",
    "                    Contig.misstart=start_align\n",
    "                    Contig.misend=end_align\n",
    "                    contig_dict[count]=Contig\n",
    "                    start_align=[]\n",
    "                    end_align=[]\n",
    "                    start_contig=[]\n",
    "                    end_contig=[]\n",
    "                    alignlength=0\n",
    "                    processid=int(data[5])\n",
    "                    if int(data[0])<=int(data[1]):\n",
    "                        start_align.append(int(data[0])+offset_add)\n",
    "                        end_align.append(int(data[1])+offset_add)\n",
    "                        alignlength=alignlength+int(data[1])-int(data[0])+1\n",
    "                    else:\n",
    "                        start_align.append(int(data[1])+offset_add)\n",
    "                        end_align.append(int(data[0])+offset_add)\n",
    "                        alignlength=alignlength+int(data[1])-int(data[0])+1\n",
    "                    start_contig.append(int(data[2]))\n",
    "                    end_contig.append(int(data[3]))\n",
    "            count=count+1\n",
    "        contig=aligncontig()\n",
    "        Contig.start=min(start_align)\n",
    "        Contig.end=max(end_align)\n",
    "        if start_contig[0]<end_contig[0]:\n",
    "               Contig.forward=1\n",
    "        else:\n",
    "               Contig.forward=2\n",
    "        Contig.misstart=start_align\n",
    "        Contig.misend=end_align\n",
    "        Contig.alignlength=alignlength\n",
    "        contig_dict[processid]=Contig\n",
    "        return contig_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Contig Statistics (NX and NAX were calculated by Quast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate NC for Contig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    class contigcov:#class to store contig length and coverage,\n",
    "        def __init__(self,length,coverage):\n",
    "            self.length=length\n",
    "            self.coverage=coverage\n",
    "    class uncovered:#class for uncovered genomic regions,\n",
    "        def __init__(self, start, end, length):\n",
    "            self.start=start\n",
    "            self.end=end\n",
    "            self.length=length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CalculateNCx_contig(alignment,ref_len):\n",
    "        list_contig_cov=[]\n",
    "        uncovered_region=[]\n",
    "        NCx=[]\n",
    "        nowlength=0\n",
    "        lastlength=0\n",
    "        laststart=0\n",
    "        lastend=0\n",
    "        index=0\n",
    "        ref_len=ref_len*1000000\n",
    "        total_uncover=ref_len\n",
    "        total_uncoverold=0\n",
    "        alignlen=[]\n",
    "        init=uncovered(1,ref_len,ref_len)\n",
    "        uncovered_region.append(init)\n",
    "        for key,value in alignment.items():\n",
    "            alignlen.append(value)\n",
    "        alignlen.sort(key=operator.attrgetter('alignlength'),reverse=True)\n",
    "        index=0\n",
    "        for contig in alignlen:\n",
    "            index+=1\n",
    "            start=contig.misstart\n",
    "            end=contig.misend\n",
    "            if contig.start==laststart and contig.end==lastend:\n",
    "                continue\n",
    "            else:\n",
    "                laststart=contig.start\n",
    "                lastend=contig.end\n",
    "            total_uncoverold=total_uncover\n",
    "            for i in range(len(start)):\n",
    "                total_uncover=0\n",
    "                uncovered_regionold=uncovered_region\n",
    "                uncovered_region=[]\n",
    "                for region in uncovered_regionold: \n",
    "                    if region.start>=end[i]:\n",
    "                        uncovered_region.append(region)\n",
    "                        total_uncover+=region.length\n",
    "                    elif region.end<=start[i]:\n",
    "                        uncovered_region.append(region)                                                                                                           \n",
    "                        total_uncover+=region.length\n",
    "                    elif region.start<=end[i] and region.end>=end[i]:\n",
    "                        if start[i]>=region.start:\n",
    "                            length1=start[i]-region.start\n",
    "                            length2=region.end-end[i]\n",
    "                            unregion1=uncovered(region.start,start[i]-1,length1)\n",
    "                            unregion2=uncovered(end[i]+1,region.end,length2)\n",
    "                            uncovered_region.append(unregion1)\n",
    "                            uncovered_region.append(unregion2)\n",
    "                            total_uncover=total_uncover+length1+length2\n",
    "                        elif start[i]<=region.start:\n",
    "                            length1=region.end-end[i]\n",
    "                            unregion=uncovered(end[i]+1,region.end,length1)   \n",
    "                            uncovered_region.append(unregion)\n",
    "                            total_uncover=total_uncover+length1\n",
    "                    elif region.end<=end[i] and region.end>=start[i]:\n",
    "                        if start[i]>=region.start:\n",
    "                            length1=start[i]-region.start\n",
    "                            unregion=uncovered(region.start,start[i]-1,length1)\n",
    "                            uncovered_region.append(unregion)\n",
    "                            total_uncover=total_uncover+length1\n",
    "            lastlength=ref_len-total_uncoverold\n",
    "            nowlength=ref_len-total_uncover \n",
    "            list_contig_cov.append(contigcov(contig.alignlength/1000000,nowlength/ref_len))\n",
    "            if lastlength<ref_len*0.1 and nowlength>=ref_len*0.1:\n",
    "                NCx.append(contig.alignlength/1000000)\n",
    "            if lastlength<ref_len*0.2 and nowlength>=ref_len*0.2:\n",
    "                NCx.append(contig.alignlength/1000000)\n",
    "            if lastlength<ref_len*0.3 and nowlength>=ref_len*0.3:\n",
    "                NCx.append(contig.alignlength/1000000)\n",
    "            if lastlength<ref_len*0.4 and nowlength>=ref_len*0.4:\n",
    "                NCx.append(contig.alignlength/1000000)\n",
    "            if lastlength<ref_len*0.5 and nowlength>=ref_len*0.5:\n",
    "                NCx.append(contig.alignlength/1000000)\n",
    "            if lastlength<ref_len*0.6 and nowlength>=ref_len*0.6:\n",
    "                NCx.append(contig.alignlength/1000000)\n",
    "            if lastlength<ref_len*0.7 and nowlength>=ref_len*0.7:\n",
    "                NCx.append(contig.alignlength/1000000)\n",
    "            if lastlength<ref_len*0.8 and nowlength>=ref_len*0.8:\n",
    "                NCx.append(contig.alignlength/1000000)\n",
    "            if lastlength<ref_len*0.9 and nowlength>=ref_len*0.9:\n",
    "                NCx.append(contig.alignlength/1000000)\n",
    "            if lastlength<ref_len and nowlength>=ref_len:\n",
    "                NCx.append(contig.alignlength/1000000)\n",
    "        return NCx,list_contig_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Input Scaffold alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class scaffolding(object):\n",
    "          def __init__(self):\n",
    "            self.scaffold_len=0\n",
    "            self.contig_num=0\n",
    "            self.pro_correct=0\n",
    "            self.pro_error=0\n",
    "            self.pro_skip=0\n",
    "            self.contigalign_start=[]\n",
    "            self.contigalign_end=[]\n",
    "def analyze_scaffold_info(info_file,align_contig):\n",
    "        f_info = open(info_file,\"r\")\n",
    "        scaffold_dict1 = defaultdict(list) #contig id,\n",
    "        scaffold_dict2 = defaultdict(list) #the order of contigs in scaffold based on assembly,\n",
    "        scaffold_dict3 = defaultdict(list) #contig end position,\n",
    "        scaffold_dict4 = defaultdict(list) #the order of contigs in scaffold based on alignment,\n",
    "        scaffold_dict5 = defaultdict(list) #contig alignment length,\n",
    "        scaffold_dict6 = defaultdict(list) #contig start list,\n",
    "        scaffold_dict7 = defaultdict(list) #contig end list,\n",
    "        total=0\n",
    "        for line in f_info:\n",
    "            data = line.rsplit()\n",
    "            scaffold_id = int(data[0])\n",
    "            contig_id = int(data[1])\n",
    "            contig_order = int(data[2])\n",
    "            if contig_id in list(align_contig.keys()):\n",
    "                scaffold_dict1[scaffold_id].append(contig_id)\n",
    "                scaffold_dict2[scaffold_id].append(contig_order)\n",
    "                scaffold_dict3[scaffold_id].append(align_contig[contig_id].end)\n",
    "                scaffold_dict5[scaffold_id].append(align_contig[contig_id].alignlength)\n",
    "                scaffold_dict6[scaffold_id].extend(align_contig[contig_id].misstart)\n",
    "                scaffold_dict7[scaffold_id].extend(align_contig[contig_id].misend)\n",
    "        scaffoldlist=[]\n",
    "        for key,value in scaffold_dict3.items():\n",
    "            if len(value) > 1:\n",
    "                count_correct = 0\n",
    "                count_err = 0\n",
    "                count_skip = 0\n",
    "                scaffold_dict4[key] = sorted(value)\n",
    "                scaffold_info=scaffolding()\n",
    "                scaffold_info.contig_num=len(scaffold_dict3[key])\n",
    "                scaffold_info.contigalign_start=scaffold_dict6[key]\n",
    "                scaffold_info.contigalign_end=scaffold_dict7[key]\n",
    "                for i in range(len(scaffold_dict3[key])-1):\n",
    "                    contig_id_a = scaffold_dict1[key][i]\n",
    "                    contig_id_b = scaffold_dict1[key][i+1]\n",
    "                    a = scaffold_dict3[key][i]\n",
    "                    b = scaffold_dict3[key][i+1]\n",
    "                    idx_a = scaffold_dict4[key].index(a)\n",
    "                    idx_b = scaffold_dict4[key].index(b)\n",
    "                    if idx_a + 1 ==  idx_b and align_contig[contig_id_a].forward ==1 and align_contig[contig_id_b].forward==1:\n",
    "                        count_correct += 1\n",
    "                    elif idx_a -1 ==idx_b and align_contig[contig_id_a].forward ==2 and align_contig[contig_id_b].forward==2:\n",
    "                        count_correct += 1\n",
    "                    elif idx_a +1 < idx_b and align_contig[contig_id_a].forward ==1 and align_contig[contig_id_b].forward==1:\n",
    "                        count_skip += 1\n",
    "                    elif idx_a -1 > idx_b and align_contig[contig_id_a].forward ==2 and align_contig[contig_id_b].forward==2:\n",
    "                        count_skip += 1\n",
    "                    else:\n",
    "                        count_err += 1    \n",
    "                    scaffold_info.scaffold_len=scaffold_info.scaffold_len+scaffold_dict5[key][i]/1000000\n",
    "                scaffold_info.scaffold_len=scaffold_info.scaffold_len+scaffold_dict5[key][-1]/1000000\n",
    "                scaffold_info.pro_correct=count_correct*100/(scaffold_info.contig_num-1)\n",
    "                scaffold_info.pro_error=count_err*100/(scaffold_info.contig_num-1)\n",
    "                scaffold_info.pro_skip=count_skip*100/(scaffold_info.contig_num-1)\n",
    "                total+=scaffold_info.scaffold_len\n",
    "            else:\n",
    "                scaffold_info=scaffolding()\n",
    "                scaffold_info.contigalign_start=scaffold_dict6[key]\n",
    "                scaffold_info.contigalign_end=scaffold_dict7[key]\n",
    "                scaffold_info.contig_num=len(scaffold_dict3[key])\n",
    "                scaffold_info.scaffold_len=scaffold_info.scaffold_len+scaffold_dict5[key][-1]/1000000\n",
    "                total+=scaffold_info.scaffold_len\n",
    "                scaffold_info.pro_correct=-1\n",
    "                scaffold_info.pro_error=-1\n",
    "                scaffold_info.pro_skip=-1\n",
    "            scaffoldlist.append(scaffold_info)\n",
    "        return scaffoldlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### block basic information (break scaffold by misscaffolding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class block(object):\n",
    "          def __init__(self):\n",
    "            self.block_num=0\n",
    "            #self.block_len=0,\n",
    "            self.block_alignlen=0\n",
    "            self.block_startlist=[]\n",
    "            self.block_endlist=[]\n",
    "def analyze_block_info(info_file,alignment):\n",
    "        f_info = open(info_file,\"r\")\n",
    "        scaffold_dict1 = defaultdict(list)\n",
    "        scaffold_dict2 = defaultdict(list)\n",
    "        scaffold_dict3 = defaultdict(list)\n",
    "        scaffold_dict4 = defaultdict(list)\n",
    "        scaffold_dict5 = defaultdict(list)\n",
    "        scaffold_dict6 = defaultdict(list)\n",
    "        scaffold_dict7 = defaultdict(list)\n",
    "        #total=0\n",
    "        for line in f_info:\n",
    "            data = line.rsplit()\n",
    "            scaffold_id = int(data[0])\n",
    "            contig_id = int(data[1])\n",
    "            if contig_id in list(alignment.keys()):\n",
    "                contig_order = int(data[2])\n",
    "                scaffold_dict1[scaffold_id].append(contig_id)\n",
    "                scaffold_dict2[scaffold_id].append(contig_order)\n",
    "                scaffold_dict3[scaffold_id].append(alignment[contig_id].end)\n",
    "                scaffold_dict5[scaffold_id].append(alignment[contig_id].alignlength)\n",
    "                scaffold_dict6[scaffold_id].extend(alignment[contig_id].misstart)\n",
    "                scaffold_dict7[scaffold_id].extend(alignment[contig_id].misend)\n",
    "        block_list=[]\n",
    "        for key,value in scaffold_dict3.items():\n",
    "                count_correct = 1\n",
    "                contig_id_a = scaffold_dict1[key][0]\n",
    "                block_len=alignment[contig_id_a].alignlength/1000000\n",
    "                block_startlist=alignment[contig_id_a].misstart[:]\n",
    "                block_endlist=alignment[contig_id_a].misend[:]\n",
    "                scaffold_dict4[key] = sorted(value)\n",
    "                for i in range(len(scaffold_dict3[key])-1):\n",
    "                    contig_id_a = scaffold_dict1[key][i]\n",
    "                    contig_id_b = scaffold_dict1[key][i+1]\n",
    "                    a = scaffold_dict3[key][i]\n",
    "                    b = scaffold_dict3[key][i+1]\n",
    "                    idx_a = scaffold_dict4[key].index(a)\n",
    "                    idx_b = scaffold_dict4[key].index(b)\n",
    "                    if idx_a + 1 ==  idx_b and alignment[contig_id_a].forward == 1 and alignment[contig_id_b].forward==1:\n",
    "                        count_correct += 1\n",
    "                        block_len+=alignment[contig_id_b].alignlength/1000000\n",
    "                        #scaffold_align_start=min(scaffold_align_start,alignment[contig_id_b].start),\n",
    "                        #scaffold_align_end=max(scaffold_align_end,alignment[contig_id_b].end),\n",
    "                        block_startlist.extend(alignment[contig_id_b].misstart)\n",
    "                        block_endlist.extend(alignment[contig_id_b].misend)\n",
    "                    elif idx_a - 1 ==  idx_b and alignment[contig_id_a].forward == 2 and alignment[contig_id_b].forward==2:\n",
    "                        count_correct += 1\n",
    "                        block_len+=alignment[contig_id_b].alignlength/1000000\n",
    "                        #scaffold_align_start=min(scaffold_align_start,alignment[contig_id_b].start),\n",
    "                        #scaffold_align_end=max(scaffold_align_end,alignment[contig_id_b].end),\n",
    "                        block_startlist.extend(alignment[contig_id_b].misstart)\n",
    "                        block_endlist.extend(alignment[contig_id_b].misend)\n",
    "                    else:\n",
    "                        BL=block()\n",
    "                        #total+=count_len\n",
    "                        BL.block_num=count_correct\n",
    "                        #BL.block_len=block_len/1000000,\n",
    "                        #BL.block_alignstart=scaffold_align_start,\n",
    "                        #BL.block_alignend=scaffold_align_end,\n",
    "                        BL.block_alignlen=block_len\n",
    "                        BL.block_startlist=block_startlist\n",
    "                        BL.block_endlist=block_endlist   \n",
    "                        block_list.append(BL)\n",
    "                        if contig_id_b in alignment:\n",
    "                            count_correct=1\n",
    "                            block_len=alignment[contig_id_b].alignlength/1000000\n",
    "                            #scaffold_align_start=alignment0[contig_id_b].start,\n",
    "                            #scaffold_align_end=alignment0[contig_id_b].end,\n",
    "                            block_startlist=alignment[contig_id_b].misstart[:]\n",
    "                            block_endlist=alignment[contig_id_b].misend[:]\n",
    "                BL=block()\n",
    "                #total+=count_len,\n",
    "                BL.block_num=count_correct\n",
    "                #BL.block_len=block_len/1000000,\n",
    "                #BL.block_alignstart=scaffold_align_start,\n",
    "                #BL.block_alignend=scaffold_align_end,\n",
    "                BL.block_alignlen=block_len\n",
    "                BL.block_startlist=block_startlist\n",
    "                BL.block_endlist=block_endlist  \n",
    "                block_list.append(BL)\n",
    "        return block_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluation for assemble scaffold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculate NX for Block (Mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CalculateNx_block(blocklist):\n",
    "        Nx=[]\n",
    "        total_length=0\n",
    "        subtotal_length=0\n",
    "        blocklist.sort(key=operator.attrgetter('block_alignlen'),reverse=True)\n",
    "        for block in blocklist:\n",
    "            total_length+=block.block_alignlen\n",
    "        for block in blocklist:\n",
    "            subtotal_length+=block.block_alignlen\n",
    "            temp=subtotal_length-block.block_alignlen\n",
    "            if temp<total_length*0.1 and subtotal_length>=total_length*0.1:\n",
    "                Nx.append(block.block_alignlen)\n",
    "            if temp<total_length*0.2 and subtotal_length>=total_length*0.2:\n",
    "                Nx.append(block.block_alignlen)\n",
    "            if temp<total_length*0.3 and subtotal_length>=total_length*0.3:\n",
    "                Nx.append(block.block_alignlen)\n",
    "            if temp<total_length*0.4 and subtotal_length>=total_length*0.4:\n",
    "                Nx.append(block.block_alignlen)\n",
    "            if temp<total_length*0.5 and subtotal_length>=total_length*0.5:\n",
    "                Nx.append(block.block_alignlen)\n",
    "            if temp<total_length*0.6 and subtotal_length>=total_length*0.6:\n",
    "                Nx.append(block.block_alignlen)\n",
    "            if temp<total_length*0.7 and subtotal_length>=total_length*0.7:\n",
    "                Nx.append(block.block_alignlen)\n",
    "            if temp<total_length*0.8 and subtotal_length>=total_length*0.8:\n",
    "                Nx.append(block.block_alignlen)\n",
    "            if temp<total_length*0.9 and subtotal_length>=total_length*0.9:\n",
    "                Nx.append(block.block_alignlen)\n",
    "            if temp<total_length and subtotal_length>=total_length:\n",
    "                Nx.append(block.block_alignlen)\n",
    "        return Nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculate NX for Scaffold (Mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CalculateNx_scaffold(scaffoldlist):\n",
    "        Nx=[]\n",
    "        total_length=0\n",
    "        subtotal_length=0\n",
    "        scaffoldlist.sort(key=operator.attrgetter('scaffold_len'),reverse=True)\n",
    "        for scaffold in scaffoldlist:\n",
    "            total_length+=scaffold.scaffold_len\n",
    "        for scaffold in scaffoldlist:\n",
    "            subtotal_length+=scaffold.scaffold_len\n",
    "            temp=subtotal_length-scaffold.scaffold_len\n",
    "            if temp<total_length*0.1 and subtotal_length>=total_length*0.1:\n",
    "                Nx.append(scaffold.scaffold_len)\n",
    "            if temp<total_length*0.2 and subtotal_length>=total_length*0.2:\n",
    "                Nx.append(scaffold.scaffold_len)\n",
    "            if temp<total_length*0.3 and subtotal_length>=total_length*0.3:\n",
    "                Nx.append(scaffold.scaffold_len)\n",
    "            if temp<total_length*0.4 and subtotal_length>=total_length*0.4:\n",
    "                Nx.append(scaffold.scaffold_len)\n",
    "            if temp<total_length*0.5 and subtotal_length>=total_length*0.5:\n",
    "                Nx.append(scaffold.scaffold_len)\n",
    "            if temp<total_length*0.6 and subtotal_length>=total_length*0.6:\n",
    "                Nx.append(scaffold.scaffold_len)\n",
    "            if temp<total_length*0.7 and subtotal_length>=total_length*0.7:\n",
    "                Nx.append(scaffold.scaffold_len)\n",
    "            if temp<total_length*0.8 and subtotal_length>=total_length*0.8:\n",
    "                Nx.append(scaffold.scaffold_len)\n",
    "            if temp<total_length*0.9 and subtotal_length>=total_length*0.9:\n",
    "                Nx.append(scaffold.scaffold_len)\n",
    "            if temp<total_length and subtotal_length>=total_length:\n",
    "                Nx.append(scaffold.scaffold_len)\n",
    "        return Nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculate NGX for Scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def CalculateNGx_scaffold(scaffoldlist,ref_len):\n",
    "        NGx=[]\n",
    "        subtotal_length=0\n",
    "        scaffoldlist.sort(key=operator.attrgetter('scaffold_len'),reverse=True)\n",
    "        for scaffold in scaffoldlist:\n",
    "            subtotal_length+=scaffold.scaffold_len\n",
    "            temp=subtotal_length-scaffold.scaffold_len\n",
    "            if temp<ref_len*0.1 and subtotal_length>=ref_len*0.1:\n",
    "                NGx.append(scaffold.scaffold_len)\n",
    "            if temp<ref_len*0.2 and subtotal_length>=ref_len*0.2:\n",
    "                NGx.append(scaffold.scaffold_len)\n",
    "            if temp<ref_len*0.3 and subtotal_length>=ref_len*0.3:\n",
    "                NGx.append(scaffold.scaffold_len)\n",
    "            if temp<ref_len*0.4 and subtotal_length>=ref_len*0.4:\n",
    "                NGx.append(scaffold.scaffold_len)\n",
    "            if temp<ref_len*0.5 and subtotal_length>=ref_len*0.5:\n",
    "                NGx.append(scaffold.scaffold_len)\n",
    "            if temp<ref_len*0.6 and subtotal_length>=ref_len*0.6:\n",
    "                NGx.append(scaffold.scaffold_len)\n",
    "            if temp<ref_len*0.7 and subtotal_length>=ref_len*0.7:\n",
    "                NGx.append(scaffold.scaffold_len)\n",
    "            if temp<ref_len*0.8 and subtotal_length>=ref_len*0.8:\n",
    "                NGx.append(scaffold.scaffold_len)\n",
    "            if temp<ref_len*0.9 and subtotal_length>=ref_len*0.9:\n",
    "                NGx.append(scaffold.scaffold_len)\n",
    "            if temp<ref_len and subtotal_length>=ref_len:\n",
    "                NGx.append(scaffold.scaffold_len)\n",
    "        return NGx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate NGX for block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CalculateNGx_block(blocklist,ref_len):\n",
    "        NGx=[]\n",
    "        total_length=0\n",
    "        subtotal_length=0\n",
    "        blocklist.sort(key=operator.attrgetter('block_alignlen'),reverse=True)\n",
    "        for block in blocklist:\n",
    "            subtotal_length+=block.block_alignlen\n",
    "            temp=subtotal_length-block.block_alignlen\n",
    "            if temp<ref_len*0.1 and subtotal_length>=ref_len*0.1:\n",
    "                NGx.append(block.block_alignlen)\n",
    "            if temp<ref_len*0.2 and subtotal_length>=ref_len*0.2:\n",
    "                NGx.append(block.block_alignlen)\n",
    "            if temp<ref_len*0.3 and subtotal_length>=ref_len*0.3:\n",
    "                NGx.append(block.block_alignlen)\n",
    "            if temp<ref_len*0.4 and subtotal_length>=ref_len*0.4:\n",
    "                NGx.append(block.block_alignlen)\n",
    "            if temp<ref_len*0.5 and subtotal_length>=ref_len*0.5:\n",
    "                NGx.append(block.block_alignlen)\n",
    "            if temp<ref_len*0.6 and subtotal_length>=ref_len*0.6:\n",
    "                NGx.append(block.block_alignlen)\n",
    "            if temp<ref_len*0.7 and subtotal_length>=ref_len*0.7:\n",
    "                NGx.append(block.block_alignlen)\n",
    "            if temp<ref_len*0.8 and subtotal_length>=ref_len*0.8:\n",
    "                NGx.append(block.block_alignlen)\n",
    "            if temp<ref_len*0.9 and subtotal_length>=ref_len*0.9:\n",
    "                NGx.append(block.block_alignlen)\n",
    "            if temp<ref_len and subtotal_length>=ref_len:\n",
    "                NGx.append(block.block_alignlen)\n",
    "        return NGx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate NCX for scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CalculateNCx_scaffold(align_scaffold,ref_len):\n",
    "        list_contig_cov=[]\n",
    "        uncovered_region=[]\n",
    "        NCx=[]\n",
    "        nowlength=0\n",
    "        lastlength=0\n",
    "        laststart=0\n",
    "        lastend=0\n",
    "        index=0\n",
    "        ref_len=ref_len*1000000\n",
    "        total_uncover=ref_len\n",
    "        total_uncoverold=0\n",
    "        init=uncovered(1,ref_len,ref_len)\n",
    "        uncovered_region.append(init)\n",
    "        align_scaffold.sort(key=operator.attrgetter('scaffold_len'),reverse=True)\n",
    "        index=0\n",
    "        A=0\n",
    "        for scaffold in align_scaffold:\n",
    "            index+=1\n",
    "            start=scaffold.contigalign_start\n",
    "            end=scaffold.contigalign_end\n",
    "            total_uncoverold=total_uncover\n",
    "            for i in range(len(start)):\n",
    "                total_uncover=0\n",
    "                uncovered_regionold=uncovered_region\n",
    "                uncovered_region=[]\n",
    "                for region in uncovered_regionold:\n",
    "                    if region.start>=end[i]:\n",
    "                        uncovered_region.append(region)\n",
    "                        total_uncover+=region.length\n",
    "                    elif region.end<=start[i]:\n",
    "                        uncovered_region.append(region)    \n",
    "                        total_uncover+=region.length\n",
    "                    elif region.start<=end[i] and region.end>=end[i]:\n",
    "                        if start[i]>=region.start:\n",
    "                            length1=start[i]-region.start\n",
    "                            length2=region.end-end[i]\n",
    "                            unregion1=uncovered(region.start,start[i]-1,length1)\n",
    "                            unregion2=uncovered(end[i]+1,region.end,length2)\n",
    "                            uncovered_region.append(unregion1)\n",
    "                            uncovered_region.append(unregion2)\n",
    "                            total_uncover=total_uncover+length1+length2\n",
    "                        elif start[i]<=region.start:\n",
    "                            length1=region.end-end[i]\n",
    "                            unregion=uncovered(end[i]+1,region.end,length1)\n",
    "                            uncovered_region.append(unregion)\n",
    "                            total_uncover=total_uncover+length1\n",
    "                    elif region.end<=end[i] and region.end>=start[i]:\n",
    "                        if start[i]>=region.start:\n",
    "                            length1=start[i]-region.start\n",
    "                            unregion=uncovered(region.start,start[i]-1,length1)\n",
    "                            uncovered_region.append(unregion)\n",
    "                            total_uncover=total_uncover+length1\n",
    "            lastlength=ref_len-total_uncoverold\n",
    "            nowlength=ref_len-total_uncover\n",
    "            list_contig_cov.append(contigcov(scaffold.scaffold_len,nowlength/ref_len))\n",
    "            if lastlength<ref_len*0.1 and nowlength>=ref_len*0.1:\n",
    "                NCx.append(scaffold.scaffold_len)\n",
    "            if lastlength<ref_len*0.2 and nowlength>=ref_len*0.2:\n",
    "                NCx.append(scaffold.scaffold_len)\n",
    "            if lastlength<ref_len*0.3 and nowlength>=ref_len*0.3:\n",
    "                NCx.append(scaffold.scaffold_len)\n",
    "            if lastlength<ref_len*0.4 and nowlength>=ref_len*0.4:\n",
    "                NCx.append(scaffold.scaffold_len)\n",
    "            if lastlength<ref_len*0.5 and nowlength>=ref_len*0.5:\n",
    "                NCx.append(scaffold.scaffold_len)\n",
    "            if lastlength<ref_len*0.6 and nowlength>=ref_len*0.6:\n",
    "                NCx.append(scaffold.scaffold_len)\n",
    "            if lastlength<ref_len*0.7 and nowlength>=ref_len*0.7:\n",
    "                NCx.append(scaffold.scaffold_len)\n",
    "            if lastlength<ref_len*0.8 and nowlength>=ref_len*0.8:\n",
    "                NCx.append(scaffold.scaffold_len)\n",
    "            if lastlength<ref_len*0.9 and nowlength>=ref_len*0.9:\n",
    "                NCx.append(scaffold.scaffold_len)\n",
    "            if lastlength<ref_len and nowlength>=ref_len:\n",
    "                NCx.append(scaffold.scaffold_len)\n",
    "        return NCx,list_contig_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate NCX for block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CalculateNCx_block(align_block,ref_len):\n",
    "        list_contig_cov=[]\n",
    "        uncovered_region=[]\n",
    "        NCx=[]\n",
    "        nowlength=0\n",
    "        lastlength=0\n",
    "        laststart=0\n",
    "        lastend=0\n",
    "        index=0\n",
    "        ref_len=ref_len*1000000\n",
    "        total_uncover=ref_len\n",
    "        total_uncoverold=0\n",
    "        init=uncovered(1,ref_len,ref_len)\n",
    "        uncovered_region.append(init)\n",
    "        align_block.sort(key=operator.attrgetter('block_alignlen'),reverse=True)\n",
    "        index=0\n",
    "        A=0\n",
    "        for block in align_block:\n",
    "            index+=1\n",
    "            start=block.block_startlist\n",
    "            end=block.block_endlist\n",
    "            total_uncoverold=total_uncover\n",
    "            for i in range(len(start)):\n",
    "                total_uncover=0\n",
    "                uncovered_regionold=uncovered_region\n",
    "                uncovered_region=[]\n",
    "                for region in uncovered_regionold:\n",
    "                    if region.start>=end[i]:\n",
    "                        uncovered_region.append(region)\n",
    "                        total_uncover+=region.length\n",
    "                    elif region.end<=start[i]:\n",
    "                        uncovered_region.append(region)  \n",
    "                        total_uncover+=region.length\n",
    "                    elif region.start<=end[i] and region.end>=end[i]:\n",
    "                        if start[i]>=region.start:\n",
    "                            length1=start[i]-region.start\n",
    "                            length2=region.end-end[i]\n",
    "                            unregion1=uncovered(region.start,start[i]-1,length1)\n",
    "                            unregion2=uncovered(end[i]+1,region.end,length2)\n",
    "                            uncovered_region.append(unregion1)\n",
    "                            uncovered_region.append(unregion2)\n",
    "                            total_uncover=total_uncover+length1+length2\n",
    "                        elif start[i]<=region.start:\n",
    "                            length1=region.end-end[i]\n",
    "                            unregion=uncovered(end[i]+1,region.end,length1)   \n",
    "                            uncovered_region.append(unregion)\n",
    "                            total_uncover=total_uncover+length1\n",
    "                    elif region.end<=end[i] and region.end>=start[i]:\n",
    "                        if start[i]>=region.start:\n",
    "                            length1=start[i]-region.start\n",
    "                            unregion=uncovered(region.start,start[i]-1,length1)\n",
    "                            uncovered_region.append(unregion)\n",
    "                            total_uncover=total_uncover+length1\n",
    "            lastlength=ref_len-total_uncoverold\n",
    "            nowlength=ref_len-total_uncover \n",
    "            list_contig_cov.append(contigcov(block.block_alignlen,nowlength/ref_len))\n",
    "            if lastlength<ref_len*0.1 and nowlength>=ref_len*0.1:\n",
    "                NCx.append(block.block_alignlen)\n",
    "            if lastlength<ref_len*0.2 and nowlength>=ref_len*0.2:\n",
    "                NCx.append(block.block_alignlen)\n",
    "            if lastlength<ref_len*0.3 and nowlength>=ref_len*0.3:\n",
    "                NCx.append(block.block_alignlen)\n",
    "            if lastlength<ref_len*0.4 and nowlength>=ref_len*0.4:\n",
    "                NCx.append(block.block_alignlen)\n",
    "            if lastlength<ref_len*0.5 and nowlength>=ref_len*0.5:\n",
    "                NCx.append(block.block_alignlen)\n",
    "            if lastlength<ref_len*0.6 and nowlength>=ref_len*0.6:\n",
    "                NCx.append(block.block_alignlen)\n",
    "            if lastlength<ref_len*0.7 and nowlength>=ref_len*0.7:\n",
    "                NCx.append(block.block_alignlen)\n",
    "            if lastlength<ref_len*0.8 and nowlength>=ref_len*0.8:\n",
    "                NCx.append(block.block_alignlen)\n",
    "            if lastlength<ref_len*0.9 and nowlength>=ref_len*0.9:\n",
    "                NCx.append(block.block_alignlen)\n",
    "            if lastlength<ref_len and nowlength>=ref_len:\n",
    "                NCx.append(block.block_alignlen)\n",
    "        return NCx,list_contig_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_NCX_contig(outpath, prefix, labellist,chr_len,chr_id,totallength):\n",
    "    alignpath=outpath+'/'+prefix+'/'+'contigs_reports/'\n",
    "    Contig_NC50=[]\n",
    "    Contig_NCA50=[]\n",
    "    NC_infolist=[]\n",
    "    NCA_infolist=[]\n",
    "    for label in labellist:\n",
    "        filename=alignpath+'all_alignments_'+label+'.tsv'\n",
    "        contig=alignment_contig_coordinate(filename,chr_id,chr_len)\n",
    "        block=alignment_miss_contig(filename,chr_id,chr_len)\n",
    "        NC_infolist.append(contig)\n",
    "        NCA_infolist.append(block)\n",
    "        [NC_contig,list_NC_contig]=CalculateNCx_contig(contig,totallength)\n",
    "        [NCA_contig,list_NCA_contig]=CalculateNCx_contig(block,totallength)\n",
    "        if len(NC_contig)<5:\n",
    "            Contig_NC50.append(0)\n",
    "        else:\n",
    "            Contig_NC50.append(NC_contig[4]*1000)\n",
    "        if len(NCA_contig)<5:\n",
    "            Contig_NCA50.append(0)\n",
    "        else:\n",
    "            Contig_NCA50.append(NCA_contig[4]*1000)\n",
    "    return Contig_NC50,ContigNCA50,NC_infolist,NCA_infolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_stat_scaffold(outdir,infolist,NC_infolist,NCA_infolist,totallength):\n",
    "    index=0\n",
    "    Scaffold_N50=[]\n",
    "    Scaffold_NA50=[]\n",
    "    Scaffold_NC50=[]\n",
    "    Scaffold_NCA50=[]\n",
    "    for info in infolist:\n",
    "        align_scaffold=analyze_scaffold_info(outdir+info,NC_infolist[index])\n",
    "        align_block=analyze_block_info(outdir+info,NCA_infolist[index])\n",
    "        NX_scaffold=CalculateNx_scaffold(align_scaffold)\n",
    "        NAX_block=CalculateNx_block(align_block)\n",
    "        [NC_scaffold,list_NC_scaffold]=CalculateNCx_scaffold(align_scaffold,totallength)\n",
    "        [NC_block,list_NC_block]=CalculateNCx_block(align_block,totallength)\n",
    "        if len(NX_scaffold)<5:\n",
    "            Scaffold_N50.append(0)\n",
    "        else:\n",
    "            Scaffold_N50.append(NX_scaffold[4])\n",
    "        if len(NX_block)<5:\n",
    "            Scaffold_NA50.append(0)\n",
    "        else:\n",
    "            Scaffold_NA50.append(NAX_block[4])\n",
    "        if len(NC_scaffold)<5:\n",
    "            Scaffold_NC50.append(0)\n",
    "        else:\n",
    "            Scaffold_NC50.append(NC_scaffold[4])\n",
    "        if len(NC_block)<5:\n",
    "            Scaffold_NCA50.append(0)\n",
    "        else:\n",
    "            Scaffold_NCA50.append(NC_block[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if function==\"Denovoall\"\n",
    "    def invoke_supernova(supernovapath, inpath, outpath, prefix, maxreads, style):\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
